# 4.5.3 AI-Powered Challenge Generation
## 4.5.3.1 Request Classification System

### Figure X4: CTF Request Classifier System Prompt Definition

The Request Classification System initializes by importing the OpenAI client library and dotenv, creating an OpenAI client instance with API key from environment variables. The core classification logic is defined through a SYSTEM_PROMPT constant that instructs the AI model to function as a CTF request classifier, categorizing user messages into four categories: Create (new challenges with specific vulnerability/service details like SQL injection, FTP, or EternalBlue, excluding vague requests), Deploy (launching existing challenges using keywords "deploy", "run", "start", "launch", "spin up"), ChallengeInfo (inquiries about specific challenges using "what is", "how does", "explain"), and Question (general cybersecurity questions, platform inquiries, or vague requests requiring clarification). The system prompt mandates a strict JSON response format containing category, confidence score (0.0-1.0), reasoning, challenge type detection (web, network, pwn, crypto, misc), and required tools array including both specialized and basic tools essential for each challenge category.

### Figure X5: OpenAI Message Classification Function with Retry Mechanism

The classification function implements an asynchronous workflow that processes user messages through OpenAI's GPT-4 model with retry logic (maximum three attempts) to ensure reliable classification under network instability or API rate limiting. The function accepts a message parameter and optional conversationHistory array, enabling context-aware classification that detects confirmation patterns ("yes", "create that", "do that") and incorporates relevant context from recent conversation history. Each retry attempt constructs a chat completion request with the system prompt, user message with optional context, temperature 0.3 for focused responses, max_tokens 200, and JSON object response format enforcement. Upon receiving the API response, the function extracts content, removes markdown code blocks if present, applies regex matching to extract JSON objects, and parses the structure. The system validates that the returned category matches predefined valid categories (Create, Deploy, ChallengeInfo, Question), normalizes the response by setting defaults for challengeType, challengeTypes array, and requiredTools if missing, and enhances requiredTools by automatically appending basic tools specific to each challenge type (burpsuite/sqlmap for web, nmap/wireshark for network, gdb/pwntools for pwn, hashcat/openssl for crypto) plus universal tools (python3, bash, git, vim, curl). If all retry attempts fail, the system falls back to keyword-based pattern matching using regular expressions to detect challenge creation, deployment, or information inquiry keywords, defaulting to general question classification with appropriate confidence scores and reasoning.

