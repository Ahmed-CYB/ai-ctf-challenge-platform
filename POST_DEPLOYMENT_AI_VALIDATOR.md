# Stage 5: Post-Deployment AI Validator

## Overview

The **Post-Deployment AI Validator** is an optional but critical validation stage that runs **after** a challenge has been deployed. It uses **OpenAI GPT-4** to analyze the deployed challenge and determine if it's **functionally correct and ready for users**.

**Key Difference**: Unlike Stage 3 (Pre-Deployment), which checks **deployment configuration**, Stage 5 validates **challenge functionality** - whether the challenge actually works as intended.

---

## When It Runs

The Post-Deployment AI Validator runs:

1. **After deployment** (`docker compose up` completes successfully)
2. **Automatically** when a challenge is deployed via the Deploy Agent
3. **Manually** when explicitly requested by the user
4. **Optional** - can be disabled, but recommended for quality assurance

**Location**: `packages/ctf-automation/src/agents/validator-agent.js`

---

## What It Does

### Step 1: Load Challenge Metadata
- Retrieves challenge metadata (name, description, category, difficulty, flag)
- Validates metadata exists and is complete

### Step 2: Deploy Challenge
- Deploys the challenge using `docker compose up`
- Creates isolated network with private IPs
- Starts victim and attacker containers
- Uses `userId: 'validator'` for validation subnet allocation

### Step 3: Wait for Services
- Waits **30 seconds** for services to fully initialize
- Allows containers time to start all services (FTP, SMB, HTTP, SSH, etc.)

### Step 4: Run Automated Tests
Performs comprehensive automated tests:

#### 4.1 Container Health Checks
- âœ… Verifies victim container is running
- âœ… Verifies attacker (Kali) container is running
- âœ… Checks container status and health
- âœ… Verifies services are listening on expected ports

#### 4.2 Network Connectivity Tests
- âœ… Verifies containers are on the same network
- âœ… Tests ping from attacker to victim
- âœ… Checks network isolation (containers can communicate)

#### 4.3 Service Port Tests
- âœ… Tests HTTP connectivity (port 80, 8080)
- âœ… Verifies services are responding
- âœ… Checks service response codes

#### 4.4 VNC Service Check (Attacker)
- âœ… Verifies VNC service is running (for GUI access)
- âœ… Checks if desktop environment is available

### Step 5: Flag Verification (CRITICAL)
**This is the most important check**:

- ðŸ” Searches for flag in **11 common locations**:
  - `/flag.txt`
  - `/root/flag.txt`
  - `/home/flag.txt`
  - `/home/ctf/flag.txt`
  - `/home/ftp/flag.txt`
  - `/srv/ftp/flag.txt`
  - `/var/www/html/flag.txt`
  - `/var/www/flag.txt`
  - `/tmp/flag.txt`
  - `/opt/flag.txt`
  - `/app/flag.txt`

- âœ… **Verifies flag content matches expected value** from metadata
- âœ… Checks if flag is accessible (can be read)
- âŒ **FAILS if flag is not found or doesn't match**

### Step 6: AI Analysis (OpenAI GPT-4)
Sends all test results to GPT-4 for intelligent analysis:

**Input to AI**:
- Challenge metadata (name, description, category, difficulty)
- Deployment information (victim IP, attacker IP, subnet)
- All automated test results
- Flag verification results

**AI Analysis**:
- Analyzes test results holistically
- Determines if challenge is **functionally correct**
- Assesses if challenge is **exploitable**
- Provides **PASS/FAIL verdict** with reasoning
- Gives **recommendations** if issues found

**AI Response Format**:
```json
{
  "status": "PASS" or "FAIL",
  "verdict": "Brief summary",
  "details": "Detailed explanation",
  "recommendations": ["List of recommendations"],
  "readyForUser": true or false,
  "confidence": "high" or "medium" or "low"
}
```

---

## Validation Criteria

### âœ… **MUST PASS (Critical)**:
1. **Victim container is running**
2. **Attacker container is running**
3. **FLAG IS FOUND and MATCHES expected value** â­ **MOST CRITICAL**
4. **Containers are on the same network**

### âš ï¸ **NICE TO HAVE (Not critical for PASS)**:
- HTTP service responding (some challenges may not use HTTP)
- Ping connectivity (some containers may have ICMP disabled)
- VNC service (usually takes time to start)

### AI Decision Logic:
- âœ… **If flag is found and matches, and containers are running** â†’ **LIKELY PASS**
- âŒ **If flag is not found or doesn't match** â†’ **FAIL** (critical issue)
- âœ… **If containers are running but network tests fail** â†’ **Still PASS if flag is correct** (network restrictions are normal)
- **Focus**: Whether the challenge is **FUNCTIONAL**, not perfect

---

## Automated Tests Performed

### Test 1: Victim Container Health
```javascript
// Checks if victim container is running
const victimInfo = await victimContainer.inspect();
results.victimAccessible = victimInfo.State.Running;

// Checks if service is listening on port 8080
netstat -tuln | grep :8080
```

### Test 2: Attacker Container Health
```javascript
// Checks if attacker (Kali) container is running
const attackerInfo = await attackerContainer.inspect();
results.attackerAccessible = attackerInfo.State.Running;

// Checks if VNC service is running
ps aux | grep vnc
```

### Test 3: Network Connectivity
```javascript
// Verifies containers are on same network
const networkInfo = await dockerManager.getNetworkInfo(networkName);
results.networkConnectivity = (containers.length >= 2);
```

### Test 4: Ping Test (Attacker â†’ Victim)
```javascript
// Tests ping from attacker to victim
ping -c 3 -W 10 ${victimIP}
results.attackerToVictimPing = (packets received > 0);
```

### Test 5: HTTP Connectivity
```javascript
// Tests HTTP access from attacker to victim
curl -s -o /dev/null -w "%{http_code}" http://${victimIP}:8080
results.httpAccessible = (statusCode >= 200 && statusCode < 600);
```

### Test 6: Flag Verification
```javascript
// Searches for flag in common locations
for (const location of flagLocations) {
  const flagContent = await exec(`cat ${location}`);
  if (flagContent.includes(expectedFlag)) {
    return { found: true, matches: true, location };
  }
}
```

---

## Flag Verification Process

The flag verification is the **most critical** part of validation:

### 1. **Expected Flag Retrieval**
- Gets expected flag from challenge metadata
- Validates flag format: `CTF{...}`

### 2. **Flag Search**
- Searches 11 common flag locations
- Executes `cat` command in victim container for each location
- Handles file not found errors gracefully

### 3. **Flag Matching**
- Compares found flag content with expected flag
- Checks for exact match (case-sensitive)
- Reports location where flag was found

### 4. **Result**
- âœ… **PASS**: Flag found and matches expected value
- âŒ **FAIL**: Flag not found OR flag doesn't match
- âš ï¸ **WARNING**: Flag found but content doesn't match

---

## AI Analysis Details

### System Prompt
```
You are an expert CTF challenge validator. Your job is to test if a deployed CTF challenge is working correctly and ready for users.

Your task:
- Analyze the test results to determine if the challenge is functioning
- Check if containers are running
- Verify network connectivity between attacker and victim
- CRITICAL: Verify the flag is correctly placed and accessible
- Assess if the challenge appears exploitable
```

### AI Input
```json
{
  "challengeMetadata": {
    "name": "ftp-brute-force",
    "description": "...",
    "category": "network",
    "difficulty": "medium",
    "flag": "CTF{actual_flag_here}"
  },
  "deployment": {
    "victimIP": "172.23.193.10",
    "attackerIP": "172.23.193.3",
    "networkName": "...",
    "victimContainerName": "...",
    "attackerContainerName": "..."
  },
  "testResults": {
    "victimAccessible": true,
    "attackerAccessible": true,
    "networkConnectivity": true,
    "attackerToVictimPing": true,
    "httpAccessible": true,
    "flagVerification": {
      "found": true,
      "matches": true,
      "location": "/root/flag.txt"
    }
  }
}
```

### AI Output
```json
{
  "status": "PASS",
  "verdict": "Challenge is functional and ready for users",
  "details": "All critical checks passed: containers running, network connected, flag found and matches expected value. HTTP service is responding. Challenge appears exploitable.",
  "recommendations": [],
  "readyForUser": true,
  "confidence": "high"
}
```

---

## Validation Report

After validation completes, a comprehensive report is generated:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           CTF CHALLENGE VALIDATION REPORT                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“¦ Challenge: ftp-brute-force
ðŸ·ï¸  Category: network
â­ Difficulty: medium

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… VALIDATION PASSED

Challenge is functional and ready for users

All critical checks passed: containers running, network connected, 
flag found and matches expected value.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ§ª TEST RESULTS:

  ðŸŽ¯ Victim Service:
    - Accessible: âœ“ YES
    - Response Time: 45ms
    - Status Code: 200

  ðŸ¥· Attacker Machine (Kali Linux):
    - Accessible: âœ“ YES
    - Response Time: 32ms
    - Status Code: 200

  ðŸŒ Network Connectivity:
    - Status: âœ“ CONNECTED

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸš€ DEPLOYMENT INFORMATION:

  ðŸŽ¯ Victim (Challenge Target):
     URL: http://172.23.193.10:8080
     Container: ctf-ftp-brute-force-victim
     
  ðŸ¥· Attacker (Kali Linux GUI):
     Container: ctf-ftp-brute-force-attacker
     
  ðŸŒ Network: ctf-ftp-brute-force_network
  
  ðŸ“ Instructions:
     1. Connect to attacker container: docker exec -it ...
     2. The victim service is accessible at: http://victim:8080
     3. Use Kali's tools to exploit the vulnerability
     4. Find the flag (format: CTF{...})

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸŽ‰ Challenge is ready for users!
```

---

## When Validation Fails

If validation fails, the system:

1. **Cleans up containers** (removes deployed challenge)
2. **Returns detailed failure report** with:
   - What failed (containers, network, flag, etc.)
   - Recommendations for fixing
   - Test results for debugging

3. **Provides troubleshooting guidance**:
   - Common issues and solutions
   - How to manually verify
   - Next steps for fixing

---

## Integration with Deployment Flow

The validator is called automatically after deployment:

```javascript
// In deploy-agent.js or index.js
response = await deployChallenge(message, conversationHistory, session);

// After deployment, run validation
if (response.success && response.challengeName) {
  console.log('\nðŸ” Validating deployed challenge...');
  const validationResult = await validatorAgent.validateChallenge(
    response.challengeName, 
    conversationHistory, 
    progressCallback
  );
  
  if (validationResult.status === 'PASS') {
    response.message = `Challenge deployed and validated successfully!`;
    response.validation = validationResult;
  } else {
    response.message = `Challenge deployed but failed validation.`;
    response.success = false;
  }
}
```

---

## Key Features

### 1. **Comprehensive Testing**
- Tests containers, network, services, and flag
- Performs realistic connectivity tests
- Verifies challenge functionality

### 2. **Intelligent AI Analysis**
- Uses GPT-4 to analyze test results holistically
- Provides human-like reasoning
- Gives actionable recommendations

### 3. **Flag Verification (Critical)**
- **Most important check**: Ensures flag is accessible
- Searches multiple common locations
- Verifies flag content matches expected value

### 4. **Forgiving Validation**
- Focuses on functionality, not perfection
- Allows network restrictions (ICMP disabled, etc.)
- Passes if flag is correct, even if some tests fail

### 5. **Detailed Reporting**
- Comprehensive validation report
- Test results breakdown
- Deployment information
- Recommendations for improvements

---

## Comparison: Stage 3 vs Stage 5

| Aspect | Stage 3: Pre-Deployment | Stage 5: Post-Deployment |
|--------|------------------------|-------------------------|
| **When** | Before deployment | After deployment |
| **Focus** | Deployment configuration | Challenge functionality |
| **Checks** | Files, syntax, packages | Containers, network, flag |
| **AI Model** | Claude Sonnet 4.5 | OpenAI GPT-4 |
| **Purpose** | Ensure `docker compose up` works | Ensure challenge is solvable |
| **Flag Check** | Format only | **Location and content** |
| **Auto-Fix** | Yes (fixes files) | No (reports issues) |
| **Critical** | Yes (blocks deployment) | Optional (quality check) |

---

## Summary

**Stage 5: Post-Deployment AI Validator** is a comprehensive validation system that:

âœ… **Deploys the challenge** and runs automated tests  
âœ… **Verifies containers** are running and healthy  
âœ… **Tests network connectivity** between attacker and victim  
âœ… **Verifies flag location and content** (CRITICAL)  
âœ… **Uses AI (GPT-4)** to analyze results and provide verdict  
âœ… **Generates detailed report** with test results and recommendations  

**Key Purpose**: Ensure the challenge is **functionally correct and ready for users**, not just that it deploys successfully.

**Most Critical Check**: **Flag verification** - ensures the flag is accessible and matches the expected value.

**Result**: PASS/FAIL verdict with detailed reasoning and recommendations.

